model:
    checkpoint_path: ""
    use_gpu: True
    loss_reduce: True
    # image embedding layer
    use_deep_img_embedding: True
    img_emb_num_blocks: 2
    img_emb_res_block_2d_inp_dim: 1024
    img_emb_res_block_2d_out_dim: 1024
    img_emb_res_block_2d_hidden_dim: 512
    # question embedding layer
    word_emb_dim: 300
    word_emb_padding_idx: 0
    word_emb_dropout_prob: 0
    apply_word_emb_nonlinear: True
    rnn_type: "LSTM"
    rnn_num_layers: 1
    rnn_hidden_dim: 1024
    rnn_dropout_prob: 0.5
    use_last_hidden: True
    # SAAA layer
    num_stacks: 2
    qst_emb_dim: -1 # will be assigned to answer_mlp_out_dim
    img_emb_dim: 1024
    att_emb_dim: 512
    att_dropout_prob: 0.5
    # classification layer
    answer_mlp_inp_dim: -1 # will be assigned automatically
    answer_mlp_out_dim: -1 # will be assigned to num_labels
    answer_mlp_hidden_dim: [1024,]
    answer_mlp_dropout_prob: 0.5
    answer_mlp_use_batchnorm: False
    answer_mlp_nonlinear_fn: "ReLU"

train_loader:
    encoded_json_path: "data/VQA_v2.0/preprocess/encoded_qa/vqa_3000_vocab_train-val_raw/all_questions_with_answer_vocab_use_zero_token_max_qst_len_23/qa_train-val.json"
    encoded_hdf5_path: "data/VQA_v2.0/preprocess/encoded_qa/vqa_3000_vocab_train-val_raw/all_questions_with_answer_vocab_use_zero_token_max_qst_len_23/qa_train-val.h5"
    batch_size: 64
    use_gpu: True
    use_img: False
    img_size: 224
    fetching_answer_option: "all_answers"
    img_dir: "data/VQA_v2.0/images"
    feat_type: "numpy"
    feat_dir: "data/VQA_v2.0/feats/resnet_conv4_feats"
test_loader:
    encoded_json_path: "data/VQA_v2.0/preprocess/encoded_qa/vqa_3000_vocab_train-val_raw/all_questions_with_answer_vocab_use_zero_token_max_qst_len_23/qa_val_rest.json"
    encoded_hdf5_path: "data/VQA_v2.0/preprocess/encoded_qa/vqa_3000_vocab_train-val_raw/all_questions_with_answer_vocab_use_zero_token_max_qst_len_23/qa_val_rest.h5"
    batch_size: 32
    use_gpu: True
    use_img: False
    img_size: 224
    fetching_answer_option: "all_answers"
    img_dir: "data/VQA_v2.0/images"
    feat_type: "numpy"
    feat_dir: "data/VQA_v2.0/feats/resnet_conv4_feats"
optimize:
    num_epoch: 25
    init_lr: 0.001
    decay_factor: 0.5
    decay_every_epoch: 10
evaluation:
    every_eval: 1
    print_every: 50
logging:
    print_level: "DEBUG"
    write_level: "INFO"
misc:
    print_every: 100
    vis_every: -1
