model:
    checkpoint_path: ""
    use_gpu: True
    base_model_type: "saaa"
    base_model_ckpt_path:
        - "results/vqa/saaa/512dim_b1_nodrop/M0/checkpoints/checkpoint_epoch_007.pkl"
        - "results/vqa/saaa/512dim_b1_nodrop/M1/checkpoints/checkpoint_epoch_006.pkl"
        - "results/vqa/saaa/512dim_b1_nodrop/M2/checkpoints/checkpoint_epoch_007.pkl"
        - "results/vqa/saaa/512dim_b1_nodrop/M3/checkpoints/checkpoint_epoch_007.pkl"
        - "results/vqa/saaa/512dim_b1_nodrop/M4/checkpoints/checkpoint_epoch_007.pkl"
    loss_reduce: False
    vis_individual_net: False
    verbose_all: True
    save_all_net: True
    # image embedding layer
    use_deep_img_embedding: True
    img_emb_num_blocks: 1
    img_emb_res_block_2d_inp_dim: 1024
    img_emb_res_block_2d_out_dim: 1024
    img_emb_res_block_2d_hidden_dim: 512
    # question embedding layer
    word_emb_dim: 300
    word_emb_padding_idx: 0
    word_emb_dropout_prob: 0
    apply_word_emb_nonlinear: True
    rnn_type: "LSTM"
    rnn_num_layers: 1
    rnn_hidden_dim: 1024
    rnn_dropout_prob: 0
    use_last_hidden: True
    # SAAA layer
    num_stacks: 2
    qst_emb_dim: -1 # will be assigned to answer_mlp_out_dim
    img_emb_dim: 1024 # or will be assigned to img_emb2d_out_dim
    att_emb_dim: 512
    att_dropout_prob: 0
    # classification layer
    answer_mlp_inp_dim: -1 # will be assigned automatically
    answer_mlp_out_dim: -1 # will be assigned to num_labels
    answer_mlp_hidden_dim: [1024,]
    answer_mlp_dropout_prob: 0
    answer_mlp_use_batchnorm: False
    answer_mlp_nonlinear_fn: "ReLU"
    # assignment model layer
    use_assignment_model: False
    # MCL criterion
    version: "CMCL_v1"
    num_models: 5
    num_overlaps: 3
    beta: 1
    apply_curriculum_learning_after: -1
    new_loss: "CMCL_v1"

# Data loaders
train_loader:
    encoded_json_path: "data/VQA_v2.0/preprocess/encoded_qa/vqa_3000_vocab_train-val_raw/all_questions_with_answer_vocab_use_zero_token_max_qst_len_23/qa_train.json"
    encoded_hdf5_path: "data/VQA_v2.0/preprocess/encoded_qa/vqa_3000_vocab_train-val_raw/all_questions_with_answer_vocab_use_zero_token_max_qst_len_23/qa_train.h5"
    batch_size: 64
    use_gpu: True
    use_img: False
    img_size: 224
    fetching_answer_option: "all_answers"
    img_dir: "data/VQA_v2.0/images"
    feat_type: "numpy"
    feat_dir: "data/VQA_v2.0/feats/resnet_conv4_feats"
test_loader:
    encoded_json_path: "data/VQA_v2.0/preprocess/encoded_qa/vqa_3000_vocab_train-val_raw/all_questions_with_answer_vocab_use_zero_token_max_qst_len_23/qa_val.json"
    encoded_hdf5_path: "data/VQA_v2.0/preprocess/encoded_qa/vqa_3000_vocab_train-val_raw/all_questions_with_answer_vocab_use_zero_token_max_qst_len_23/qa_val.h5"
    batch_size: 32
    use_gpu: True
    use_img: False
    img_size: 224
    fetching_answer_option: "all_answers"
    img_dir: "data/VQA_v2.0/images"
    feat_type: "numpy"
    feat_dir: "data/VQA_v2.0/feats/resnet_conv4_feats"
# Optimization
optimize:
    num_epoch: 50
    init_lr: 0.0005
    decay_factor: 0.5
    decay_every_epoch: -1
evaluation:
    every_eval: 2
    print_every: 100
logging:
    print_level: "DEBUG"
    write_level: "INFO"
misc:
    print_every: 100
    vis_every: -1
